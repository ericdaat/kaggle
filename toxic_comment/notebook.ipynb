{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/code/venvs/data/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/eric/code/venvs/data/local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "from Stemmer import Stemmer\n",
    "from nltk import SnowballStemmer\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', encoding='utf8')\n",
    "df_test = pd.read_csv('test.csv', encoding='utf8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_df(df):\n",
    "    match_numbers = re.compile(r'[0-9]+', flags=re.IGNORECASE)\n",
    "    df.comment_text = df.comment_text.str.replace(match_numbers, 'NUM')\n",
    "    df.comment_text = df.comment_text.str.replace('[\\n\\,;-_\"]', ' ')\n",
    "    stemmer = SnowballStemmer('english')\n",
    "\n",
    "    df.comment_text = df.comment_text.map(lambda r: map(lambda w: stemmer.stem(w), r.split(' ')))\\\n",
    "                        .map(lambda r: ' '.join(r))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = Pipeline(steps=[('tfidf', TfidfVectorizer(ngram_range=(1, 3),\n",
    "                                              stop_words='english',\n",
    "                                              max_features=150000,\n",
    "                                              min_df=3,\n",
    "                                              max_df=0.8,\n",
    "                                              lowercase=True,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.fit(pd.concat([df_train['comment_text'],\n",
    "                 df_test['comment_text']]))\n",
    "\n",
    "X_train = p.transform(df_train['comment_text'])\n",
    "y_train = df_train.iloc[:,2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=256)\n",
    "X_train_k = svd.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack([X_train, X_train_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn multi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene',\n",
    "               'threat', 'insult', 'identity_hate']\n",
    "\n",
    "clfs = {}\n",
    "roc_aucs = []\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    clf = SGDClassifier(loss='modified_huber',\n",
    "                        n_jobs=6,\n",
    "                        alpha=0.0001,\n",
    "                        max_iter=15)\n",
    "    \n",
    "    score =  np.mean(cross_val_score(clf,\n",
    "                                     X_train,\n",
    "                                     y_train[:,i],\n",
    "                                     cv=3,\n",
    "                                     scoring='roc_auc'))\n",
    "    \n",
    "    print '\"{0}\" classifier has {1:.3f} roc_auc'.format(class_names[i], score)\n",
    "\n",
    "    clf.fit(X_train, y_train[:, i])\n",
    "    clfs[class_names[i]] = clf\n",
    "    roc_aucs.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(roc_aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = p.transform(df_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "for class_name, model in clfs.items():\n",
    "    submission_df[class_name] = model.predict_proba(X_test)[:,1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_sklearn_multi_sgd.csv',\n",
    "                     index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
