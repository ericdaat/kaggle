{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.merge(pd.read_csv('data/songs.csv'),\n",
    "                 pd.read_csv('data/song_extra_info.csv'),\n",
    "                 on = 'song_id',\n",
    "                 how='inner')\\\n",
    "          .set_index('song_id', drop=True)\n",
    "\n",
    "members = pd.read_csv('data/members.csv')\\\n",
    "            .set_index('msno', drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv').sample(20000)\n",
    "\n",
    "train = train.merge(songs, left_on='song_id', right_index=True)\\\n",
    "             .merge(members, left_on='msno', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([train.nunique(),\n",
    "           train.dtypes],\n",
    "          axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def parse_df_1(df):\n",
    "    categorical_columns = df.dtypes.loc[df.dtypes == 'object'].index.tolist()\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        df[col] = (col + '-' + df[col].str.replace(' ', '_')).fillna('')\n",
    "\n",
    "    h = HashingVectorizer(token_pattern='[\\S]+')\n",
    "\n",
    "    X = sparse.hstack([h.transform([' '.join(row) for row in df[categorical_columns].values]),])\n",
    "    y = df['target']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "for df in pd.read_csv('./data/train.csv', chunksize=1000000):\n",
    "    df = df.merge(songs, left_on='song_id', right_index=True)\\\n",
    "           .merge(members, left_on='msno', right_index=True)\n",
    "\n",
    "    train, val = train_test_split(df, shuffle=True)\n",
    "    X_train, y_train = parse_df_1(train)\n",
    "    X_val, y_val = parse_df_1(val)\n",
    "\n",
    "    clf = SGDClassifier(loss='log', max_iter=5)\n",
    "    clf.partial_fit(X_train, y_train, classes=[0, 1])\n",
    "    \n",
    "    print(roc_auc_score(clf.predict(X_val), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/code/venvs/data3/lib/python3.5/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37493, 500000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "def parse_df_2(df):\n",
    "    # df['song_length_cut'] = pd.cut(df.song_length, bins=10, labels=range(10))\n",
    "    \n",
    "    categorical_columns = df.dtypes.loc[df.dtypes == 'object'].index.tolist()\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        df[col] = (col + '-' + df[col].str.replace(' ', '_')).fillna('')\n",
    "\n",
    "    h = HashingVectorizer(n_features=500000,\n",
    "                          token_pattern='[\\S]+')\n",
    "\n",
    "    X = sparse.hstack([h.transform([' '.join(row) for row in df[categorical_columns].values]),])\n",
    "    y = df['target']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "for df in pd.read_csv('./data/train.csv', chunksize=50000):\n",
    "    df = df.merge(songs, left_on='song_id', right_index=True)\\\n",
    "           .merge(members, left_on='msno', right_index=True)\n",
    "    \n",
    "    train, val = train_test_split(df, shuffle=True)\n",
    "    X_train, y_train = parse_df_2(train)\n",
    "    X_val, y_val = parse_df_2(val)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_shape=(X_train.shape[1],),\n",
    "                    units=512,\n",
    "                    activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=256,\n",
    "                    activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=128,\n",
    "                    activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=2,\n",
    "                    activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              epochs=1,\n",
    "              validation_data=(X_val, y_val))\n",
    "    \n",
    "    print(roc_auc_score(model.predict_classes(X_val), y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_user = layers.Input(shape=(1,), dtype='int32', name='user')\n",
    "embedding_user = layers.Embedding(input_dim=50000, output_dim=64, name='embedding_user')\n",
    "embedding_user = embedding_user(i_user)\n",
    "embedding_user = layers.Flatten()(embedding_user)\n",
    "\n",
    "i_song = layers.Input(shape=(1,), dtype='int32', name='song')\n",
    "embedding_song = layers.Embedding(input_dim=50000, output_dim=64, name='embedding_song')\n",
    "embedding_song = embedding_song(i_song)\n",
    "embedding_song = layers.Flatten()(embedding_song)\n",
    "\n",
    "e_dot = layers.dot([embedding_user, embedding_song], axes=1)\n",
    "\n",
    "i_length = layers.Input(shape=(1,), dtype='float32', name='song_length')\n",
    "\n",
    "m = layers.concatenate([e_dot, i_length])\n",
    "\n",
    "h = layers.Dense(5, activation='relu')(m)\n",
    "o = layers.Dense(1, activation='sigmoid')(h)\n",
    "\n",
    "model = models.Model(inputs=[i_user, i_song, i_length],\n",
    "                     outputs=o)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_user = train['msno'].apply(lambda r: one_hot(r, filters=' ', n=50000)[0])\n",
    "x_song = train['song_id'].apply(lambda r: one_hot(r, filters=' ', n=50000)[0])\n",
    "x_length = train['song_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([x_user, x_song, x_length],\n",
    "          train['target'].values,\n",
    "          epochs=3,\n",
    "          validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('msno')['song_id'].count().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data3)",
   "language": "python",
   "name": "data3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
